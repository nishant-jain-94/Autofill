{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### importing require packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.engine import Input\n",
    "from keras.layers import Embedding, merge\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from embeddings import Embeddings\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.mean([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Instantiate Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "embeddings = Embeddings(100, 4, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### getting data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2vec_weights = embeddings.get_weights()\n",
    "word2index, index2word = embeddings.get_vocabulary()\n",
    "word2vec_model = embeddings.get_model()\n",
    "tokenized_indexed_sentences = embeddings.get_tokenized_indexed_sentences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### generating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "vocab_size = len(word2index)\n",
    "print(vocab_size)\n",
    "#sorted(window_size,reverse=True)\n",
    "#sentence_max_length = max([len(sentence) for sentence in tokenized_indexed_sentence ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_weights_path = \"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful\"\n",
    "if not os.path.exists(model_weights_path):\n",
    "    os.makedirs(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seq_in = []\n",
    "seq_out = []\n",
    "\n",
    "# generating dataset\n",
    "for sentence in tokenized_indexed_sentences:\n",
    "    sentence_seq_in = []\n",
    "    sentence_seq_out = []\n",
    "    for i in range(len(sentence)-window_size-1):\n",
    "        x = sentence[i:i + window_size]\n",
    "        y = sentence[i + window_size]\n",
    "        sentence_seq_in.append(x)#[]\n",
    "        sentence_seq_out.append(word2vec_weights[y])\n",
    "    seq_in.append(sentence_seq_in)\n",
    "    seq_out.append(sentence_seq_out)\n",
    "\n",
    "# converting seq_in and seq_out into numpy array\n",
    "seq_in = np.array(seq_in)\n",
    "seq_out = np.array(seq_out)\n",
    "n_samples = len(seq_in)\n",
    "print (\"Number of samples : \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subsamples = np.array([len(seq) for seq in seq_in])\n",
    "print(np.sum(subsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subsamples_in = np.array([s for seq in seq_in for s in seq])\n",
    "subsamples_out = np.array([s for seq in seq_out for s in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.expand_dims(seq_in[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_batches = int(subsamples_in.shape[0] / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_len = []\n",
    "for i in range(total_batches):\n",
    "    batch_len.append(len(subsamples_in[i::total_batches]))\n",
    "min_batch_len = min(batch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Changes to the model to be done here\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word2vec_weights.shape[0], output_dim=word2vec_weights.shape[1], weights=[word2vec_weights], batch_input_shape=(min_batch_len, 5)))\n",
    "model.add(LSTM(512, return_sequences=True, stateful=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, stateful=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(word2vec_weights.shape[1], activation='sigmoid'))\n",
    "model.load_weights(\"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful/weights-10-0.9673129916191101\")\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"Train\")\n",
    "for epoch in range(15):\n",
    "    print(\"Epoch {0}/{1}\".format(epoch+1, 15))\n",
    "    mean_tr_accuracy = []\n",
    "    mean_tr_loss = []\n",
    "    for i in range(total_batches):\n",
    "        # print(\"Done with {0}/{1} batches\".format(i, total_batches))\n",
    "        train_accuracy, train_loss = model.train_on_batch(subsamples_in[i::total_batches][:min_batch_len], subsamples_out[i::total_batches][:min_batch_len])\n",
    "        mean_tr_accuracy.append(train_accuracy)\n",
    "        mean_tr_loss.append(train_loss)\n",
    "#         model.reset_states()\n",
    "    mean_accuracy = np.mean(mean_tr_accuracy)\n",
    "    mean_loss = np.mean(mean_tr_loss)\n",
    "    print(\"Mean Accuracy\", mean_accuracy)\n",
    "    print(\"Mean Loss\", mean_loss)\n",
    "    filepath = \"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful/weights-{0}-{1}\".format(epoch+1, mean_accuracy, mean_loss)\n",
    "    model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start = 20\n",
    "samples = subsamples_in[start::total_batches][:min_batch_len]\n",
    "predictions = model.predict_on_batch(samples)\n",
    "for index, prediction in enumerate(predictions):\n",
    "    print(' '.join(index2word[index] for index in samples[index]))\n",
    "    pred_word = word2vec_model.similar_by_vector(prediction)[0][0]\n",
    "    sys.stdout.write(\"*\"+pred_word+\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    start = 27\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    predictions = model.predict_on_batch(subsamples_in[start::total_batches][:min_batch_len])\n",
    "    ytrue = subsamples_out[start::total_batches][:min_batch_len]\n",
    "    for index, prediction in enumerate(predictions):\n",
    "        pred_word = word2vec_model.similar_by_vector(prediction)[0][0]\n",
    "        true_word = word2vec_model.similar_by_vector(ytrue[index])[0][0]\n",
    "        sim = word2vec_model.similarity(pred_word, true_word)\n",
    "        if (sim >= 0.85):\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    accur = float(correct/(count))\n",
    "    print('accuracy = ', float(accur))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# n = no. of predictions\n",
    "print(accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
