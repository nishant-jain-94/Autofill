{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from load_from_wiki import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing_squad_data(dataset):\n",
    "    raw_data = []\n",
    "    for data in dataset['data']:\n",
    "        paragraphs = data['paragraphs']       \n",
    "        for paragraph in paragraphs:\n",
    "            para_ques_dict = {}\n",
    "            para_ques_dict['Passages'] = paragraph['context'].lower()\n",
    "            ques_list = []\n",
    "            for questions in paragraph['qas']:\n",
    "                ques_list.append(questions['question'])\n",
    "            para_ques_dict['Question'] = list(set(ques_list)) \n",
    "            raw_data.append(para_ques_dict)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_squad_dev_train():    \n",
    "    with open('../data/dev-v1.1.json') as data_file:\n",
    "        dataset = json.load(data_file)\n",
    "        dev_set = processing_squad_data(dataset)\n",
    "    with open('../data/train-v1.1.json') as data_file:\n",
    "        dataset = json.load(data_file)\n",
    "        train_set = processing_squad_data(dataset)\n",
    "    dev_set.extend(train_set)\n",
    "    with open('../data/squad_data.json', 'w') as outfile:\n",
    "        json.dump(dev_set , outfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_squad_data():\n",
    "    \"\"\"Merges two files squad_data and wiki_data and generates an merged file squad_wiki_data.json  \"\"\"\n",
    "    with open('../data/dev-v1.1.json') as data_file:\n",
    "        dataset = json.load(data_file)\n",
    "    with open('../data/train-v1.1.json') as data_file:\n",
    "        dataset1 = json.load(data_file)\n",
    "    dataset = processing_squad_data(dataset)\n",
    "    dataset1 = processing_squad_data(dataset1)\n",
    "    final_dict = {}\n",
    "    final_para = []\n",
    "    final_question = []\n",
    "    for data in dataset:\n",
    "        final_para.append(data['Passages'])\n",
    "        final_question.extend(data['Question'])\n",
    "    for data in dataset1:\n",
    "        final_para.append(data['Passages'])\n",
    "        final_question.extend(data['Question'])\n",
    "    final_dict['Paragraph'] = ''.join(final_para)\n",
    "    final_dict['Question'] = final_question\n",
    "    final_data = []\n",
    "    final_data.append(final_dict)\n",
    "    with open('../data/combined_squad_data.json','w') as outfile:\n",
    "        json.dump(final_data , outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_file():\n",
    "    \"\"\"Merges two files squad_data and wiki_data and generates an merged file squad_wiki_data.json  \"\"\"\n",
    "    with open('../data/squad_data.json') as data_file:\n",
    "        dataset1 = json.load(data_file)\n",
    "    with open('../data/wiki_data.json') as data_file:\n",
    "        dataset2 = json.load(data_file)\n",
    "    final_dict = {}\n",
    "    final_para = []\n",
    "    final_question = []\n",
    "    for data in dataset1:\n",
    "        final_para.append(data['Passages'])\n",
    "        final_question.extend(data['Question'])\n",
    "    for data in dataset2:\n",
    "        final_para.append(data['Passage'])\n",
    "        final_question.extend(data['Question'])\n",
    "    final_dict['Paragraph'] = ''.join(final_para)\n",
    "    final_dict['Question'] = final_question\n",
    "    final_data = []\n",
    "    final_data.append(final_dict)\n",
    "    with open('../data/squad_wiki_data.json','w') as outfile:\n",
    "        json.dump(final_data , outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_squad_wiki_data():\n",
    "    if not os.path.isfile(\"../data/squad_wiki_data.json\"):\n",
    "        # Check if the train-v1.1.json exists\n",
    "        if not os.path.isfile(\"../data/train-v1.1.json\"):\n",
    "            print(\"Loading Squad Training Data\")\n",
    "            response = requests.get(\"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
    "            with open(\"../data/train-v1.1.json\", \"wb\") as outfile:\n",
    "                for data in response.iter_content():\n",
    "                    outfile.write(data)\n",
    "\n",
    "        # Check if the dev-v1.1.json exists\n",
    "        if not os.path.isfile(\"../data/dev-v1.1.json\"):\n",
    "            print(\"Loading Squad Dev Data\")\n",
    "            response = requests.get(\"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
    "            with open(\"../data/dev-v1.1.json\", \"wb\") as outfile:\n",
    "                for data in response.iter_content():\n",
    "                    outfile.write(data)\n",
    "\n",
    "        # Check if the squad_data exists if not generate squad_data.json\n",
    "        if not os.path.isfile(\"../data/squad_data.json\"):\n",
    "            print(\"Combining Squad Data\")\n",
    "            combine_squad_dev_train()\n",
    "\n",
    "        # Check if the wiki_data exists else call the respective script to load it\n",
    "        if not os.path.isfile(\"../data/wiki_data.json\"):\n",
    "            print(\"Loading Wiki Data\")\n",
    "            load_data()\n",
    "\n",
    "        merge_file()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_squad_wiki_data():\n",
    "    print(\"Loading Squad Data\")\n",
    "    load_squad_wiki_data()\n",
    "    with open(\"../data/squad_wiki_data.json\", \"r\") as dataset:\n",
    "        squad_wiki_data = json.load(dataset)\n",
    "    return squad_wiki_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_squad_data():\n",
    "    print(\"Combining Squad Data\")\n",
    "    combine_squad_data()\n",
    "    with open(\"../data/combined_squad_data.json\", \"r\") as dataset:\n",
    "        squad_data = json.load(dataset)\n",
    "    return squad_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = get_squad_wiki_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type(data[0][\"Question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
