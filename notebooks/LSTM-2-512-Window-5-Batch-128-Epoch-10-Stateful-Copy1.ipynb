{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing require packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING(100,4,1,4) STARTED .....\n",
      "Loading the embeddings from the cache\n",
      "EMBEDDING(100,4,1,4) COMPLETED .....\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from keras.engine import Input\n",
    "from keras.layers import Embedding, merge\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing import sequence\n",
    "from embeddings import Embeddings\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the embeddings from the cache\n"
     ]
    }
   ],
   "source": [
    "embeddings = Embeddings(100, 4, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getting data from preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_weights = embeddings.get_weights()\n",
    "word2index, index2word = embeddings.get_vocabulary()\n",
    "word2vec_model = embeddings.get_model()\n",
    "tokenized_indexed_sentences = embeddings.get_tokenized_indexed_sentences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42047\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "vocab_size = len(word2index)\n",
    "print(vocab_size)\n",
    "#sorted(window_size,reverse=True)\n",
    "#sentence_max_length = max([len(sentence) for sentence in tokenized_indexed_sentence ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_weights_path = \"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful\"\n",
    "if not os.path.exists(model_weights_path):\n",
    "    os.makedirs(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples :  10410\n"
     ]
    }
   ],
   "source": [
    "seq_in = []\n",
    "seq_out = []\n",
    "\n",
    "# generating dataset\n",
    "for sentence in tokenized_indexed_sentences:\n",
    "    sentence_seq_in = []\n",
    "    sentence_seq_out = []\n",
    "    for i in range(len(sentence)-window_size-1):\n",
    "        x = sentence[i:i + window_size]\n",
    "        y = sentence[i + window_size]\n",
    "        sentence_seq_in.append(x)#[]\n",
    "        sentence_seq_out.append(word2vec_weights[y])\n",
    "    seq_in.append(sentence_seq_in)\n",
    "    seq_out.append(sentence_seq_out)\n",
    "\n",
    "# converting seq_in and seq_out into numpy array\n",
    "seq_in = np.array(seq_in)\n",
    "seq_out = np.array(seq_out)\n",
    "n_samples = len(seq_in)\n",
    "print (\"Number of samples : \", n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47295\n"
     ]
    }
   ],
   "source": [
    "subsamples = np.array([len(seq) for seq in seq_in])\n",
    "print(np.sum(subsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subsamples_in = np.array([s for seq in seq_in for s in seq])\n",
    "subsamples_out = np.array([s for seq in seq_out for s in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0],\n",
       "       [  31],\n",
       "       [   2],\n",
       "       [   0],\n",
       "       [1664]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(seq_in[0][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_batches = int(subsamples_in.shape[0] / 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_len = []\n",
    "for i in range(total_batches):\n",
    "    batch_len.append(len(subsamples_in[i::total_batches]))\n",
    "min_batch_len = min(batch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (257, 5, 100)             4204700   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (257, 5, 512)             1255424   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (257, 5, 512)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (257, 512)                2099200   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (257, 512)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (257, 100)                51300     \n",
      "=================================================================\n",
      "Total params: 7,610,624\n",
      "Trainable params: 7,610,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Changes to the model to be done here\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word2vec_weights.shape[0], output_dim=word2vec_weights.shape[1], weights=[word2vec_weights], batch_input_shape=(min_batch_len, 5)))\n",
    "model.add(LSTM(512, return_sequences=True, stateful=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, stateful=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(word2vec_weights.shape[1], activation='relu'))\n",
    "#model.load_weights(\"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful/weights-10-0.9673129916191101\")\n",
    "model.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4bd5452c9799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# print(\"Done with {0}/{1} batches\".format(i, total_batches))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_batch_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsamples_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_batch_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmean_tr_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmean_tr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    942\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    943\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/venvs/autofill/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "for epoch in range(1):\n",
    "    print(\"Epoch {0}/{1}\".format(epoch+1, 1))\n",
    "    mean_tr_accuracy = []\n",
    "    mean_tr_loss = []\n",
    "    for i in range(total_batches):\n",
    "        # print(\"Done with {0}/{1} batches\".format(i, total_batches))\n",
    "        train_accuracy, train_loss = model.train_on_batch(subsamples_in[i::total_batches][:min_batch_len], subsamples_out[i::total_batches][:min_batch_len])\n",
    "        mean_tr_accuracy.append(train_accuracy)\n",
    "        mean_tr_loss.append(train_loss)\n",
    "    mean_accuracy = np.mean(mean_tr_accuracy)\n",
    "    mean_loss = np.mean(mean_tr_loss)\n",
    "    print(\"Mean Accuracy\", mean_accuracy)\n",
    "    print(\"Mean Loss\", mean_loss)\n",
    "    filepath = \"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful/weights-{0}-{1}\".format(epoch+1, mean_accuracy, mean_loss)\n",
    "    model.save_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "won super bowl 50 what\n",
      "*minority \n",
      "have during the super bowl\n",
      "*minority \n",
      "bowl 50 'an important game\n",
      "*financial \n",
      "prios has the sun life\n",
      "*financial \n",
      "50 what was the last\n",
      "*minority \n",
      "15 regular season games since\n",
      "*minority \n",
      "how many interceptions are the\n",
      "*financial \n",
      "what was ronnie hillman 's\n",
      "*minority \n",
      "left in the game when\n",
      "*minority \n",
      "manning took how many different\n",
      "*financial \n",
      "player did the field problem\n",
      "*minority \n",
      "city 's marriott did the\n",
      "*minority \n",
      "former students went on to\n",
      "*minority \n",
      "money was spent on other\n",
      "*financial \n",
      "that gives local companies business\n",
      "*financial \n",
      "station could an american viewer\n",
      "*financial \n",
      "rate for a 30-second ad\n",
      "*financial \n",
      "what movie company paid to\n",
      "*minority \n",
      "british commentators include darren fletcher\n",
      "*financial \n",
      "was the pass on the\n",
      "*minority \n",
      "thought he called for a\n",
      "*financial \n",
      "who bumped the ball away\n",
      "*financial \n",
      "though he broke his arm\n",
      "*financial \n",
      "population of warsaw was jewish\n",
      "*financial \n",
      "national gallery of art organize\n",
      "*financial \n",
      "sigismund iii vasa move his\n",
      "*financial \n",
      "what does the highest level\n",
      "*minority \n",
      "of warsaw 's population was\n",
      "*minority \n",
      "part of france were the\n",
      "*financial \n",
      "of needlework was used in\n",
      "*minority \n",
      "did he sever family ties\n",
      "*financial \n",
      "tesla do for work at\n",
      "*minority \n",
      "landmark was tesla asked about\n",
      "*minority \n",
      "when tesla attempted to photograph\n",
      "*financial \n",
      "inside the lab after it\n",
      "*financial \n",
      "was tesla on his way\n",
      "*minority \n",
      "where was tesla studying when\n",
      "*minority \n",
      "can a lot tesla 's\n",
      "*minority \n",
      "term given to describe the\n",
      "*minority \n",
      "if two integers are multiplied\n",
      "*financial \n",
      "two examples of types of\n",
      "*minority \n",
      "sort integers this represents what\n",
      "*minority \n",
      "most commonly defined by what\n",
      "*minority \n",
      "for x which reduces to\n",
      "*minority \n",
      "commonly not ascribed to the\n",
      "*minority \n",
      "through this lens what type\n",
      "*minority \n",
      "how many combinatory and graph\n",
      "*financial \n",
      "for a teacher of just\n",
      "*minority \n",
      "is corporal punishment still a\n",
      "*financial \n",
      "to become more ____ about\n",
      "*minority \n",
      "what type of intervention would\n",
      "*minority \n",
      "how long are students required\n",
      "*financial \n",
      "of the english translation of\n",
      "*minority \n",
      "church money collector said that\n",
      "*minority \n",
      "much of the indulgences went\n",
      "*financial \n",
      "what did luther call the\n",
      "*minority \n",
      "taking in boarders how did\n",
      "*minority \n",
      "what work of luther 's\n",
      "*minority \n",
      "that the soul does n't\n",
      "*financial \n",
      "in response to agricola and\n",
      "*minority \n",
      "their lies whose writings were\n",
      "*financial \n",
      "did luther 's writings sound\n",
      "*financial \n",
      "what is the name of\n",
      "*minority \n",
      "california 's north - south\n",
      "*minority \n",
      "other than the 1980s in\n",
      "*minority \n",
      "each of the extended metropolitan\n",
      "*minority \n",
      "which county is developing its\n",
      "*financial \n",
      "the merger of sky television\n",
      "*financial \n",
      "was the chief executive officer\n",
      "*financial \n",
      "who was given the highlights\n",
      "*financial \n",
      "is the asian influence strongest\n",
      "*financial \n",
      "did victoria produce in the\n",
      "*minority \n",
      "what name was given to\n",
      "*minority \n",
      "what time of day did\n",
      "*minority \n",
      "other northern european cities had\n",
      "*minority \n",
      "protestant leader was educated at\n",
      "*minority \n",
      "what sort of engines utilized\n",
      "*financial \n",
      "heat for boiling water in\n",
      "*minority \n",
      "temperature of a steam turbine\n",
      "*financial \n",
      "invented a high-pressure steam engine\n",
      "*financial \n",
      "with fuel sources what concern\n",
      "*financial \n",
      "watt 's measurements on a\n",
      "*financial \n",
      "english chemist showed that fire\n",
      "*financial \n",
      "used at _____ of the\n",
      "*minority \n",
      "part of air was deemed\n",
      "*financial \n",
      "in organisms absorb singlet oxygen\n",
      "*financial \n",
      "much is the sieve method\n",
      "*minority \n",
      "calcium containing body part is\n",
      "*minority \n",
      "they raise the price of\n",
      "*minority \n",
      "the law which imposed the\n",
      "*minority \n",
      "by which year did chrysler\n",
      "*financial \n",
      "regarding america 's progress on\n",
      "*minority \n",
      "the press during a presentation\n",
      "*financial \n",
      "was the decision made to\n",
      "*minority \n",
      "was the original pilot for\n",
      "*minority \n",
      "type of materials inside the\n",
      "*minority \n",
      "what day did the apollo\n",
      "*financial \n",
      "found during the apollo 15\n",
      "*financial \n",
      "what bible book did the\n",
      "*minority \n",
      "primary constitutional sources of the\n",
      "*minority \n",
      "the 28 member states how\n",
      "*financial \n",
      "eu which court believes they\n",
      "*financial \n",
      "does the eu 's legitimacy\n",
      "*financial \n",
      "been recognized as one of\n",
      "*minority \n",
      "european council to govern mergers\n",
      "*financial \n",
      "the court of justice say\n",
      "*minority \n",
      "the freedom of establishment and\n",
      "*minority \n",
      "what country can most of\n",
      "*minority \n",
      "was the drainage basin of\n",
      "*minority \n",
      "amount of dust that travels\n",
      "*financial \n",
      "the first european to travel\n",
      "*financial \n",
      "kilometer of the amazon rainforest\n",
      "*financial \n",
      "carbon is stored in the\n",
      "*minority \n",
      "many areas were impacted by\n",
      "*minority \n",
      "ans sea anemones belong to\n",
      "*minority \n",
      "is the name of the\n",
      "*minority \n",
      "who was bill aiken 's\n",
      "*minority \n",
      "fresno neighborhood lie to the\n",
      "*minority \n",
      "lived in fresno in 2000\n",
      "*financial \n",
      "how is it delivered how\n",
      "*financial \n",
      "used for what do x25\n",
      "*financial \n",
      "companies to do what how\n",
      "*financial \n",
      "how long did the plague\n",
      "*financial \n",
      "struggling to identify the history\n",
      "*financial \n",
      "the area called where two\n",
      "*financial \n",
      "were the principle of faunal\n",
      "*financial \n",
      "that pinch into lenses are\n",
      "*financial \n",
      "precisely date rocks within the\n",
      "*minority \n",
      "city an important center of\n",
      "*minority \n",
      "of newcastle do with their\n",
      "*financial \n",
      "was 189863 according to what\n",
      "*minority \n",
      "what is the largest traveling\n",
      "*financial \n",
      "type of tunnels are constructed\n",
      "*financial \n",
      "the the church of st\n",
      "*minority \n",
      "of fine art collection at\n",
      "*minority \n",
      "va collection does the henry\n",
      "*financial \n",
      "institution did the va partnered\n",
      "*financial \n",
      "many works of art are\n",
      "*financial \n",
      "that is in the va\n",
      "*minority \n",
      "sculpture by michelangelo has a\n",
      "*financial \n",
      "which year did the va\n",
      "*minority \n",
      "which member of parliament explained\n",
      "*financial \n",
      "is the largest item from\n",
      "*minority \n",
      "designed the forest tapestry in\n",
      "*minority \n",
      "firm offered to buy the\n",
      "*financial \n",
      "the longest running program in\n",
      "*minority \n",
      "the new four-note jingle for\n",
      "*minority \n",
      "hosted the syndicated version of\n",
      "*minority \n",
      "disney want abc to invest\n",
      "*financial \n",
      "position did fred silverman leave\n",
      "*financial \n",
      "company as a syndication distributor\n",
      "*financial \n",
      "on abc 's new wednesday\n",
      "*financial \n",
      "stay on for after stepping\n",
      "*financial \n",
      "relegation to secondary status for\n",
      "*minority \n",
      "cities merger who was the\n",
      "*minority \n",
      "the logo were used to\n",
      "*minority \n",
      "of ghengis khan and börte\n",
      "*financial \n",
      "genghis khan capture the jin\n",
      "*financial \n",
      "the mongols shield themselves with\n",
      "*minority \n",
      "of genghis khan 's sons\n",
      "*financial \n",
      "that governed military and civilian\n",
      "*financial \n",
      "route did genghis khan bring\n",
      "*financial \n",
      "which mongol conqueror was most\n",
      "*financial \n",
      "do pharmacists acquire more preparation\n",
      "*financial \n",
      "what types of diseases are\n",
      "*financial \n",
      "are the agents the immune\n",
      "*minority \n",
      "organisms what is the dominant\n",
      "*minority \n",
      "recognized by what receptor on\n",
      "*minority \n",
      "cell causes it to release\n",
      "*minority \n",
      "less sun and produce less\n",
      "*financial \n",
      "of system of infection involves\n",
      "*minority \n",
      "system by which prokaryotes retain\n",
      "*financial \n",
      "that can be transformed into\n",
      "*minority \n",
      "inspired by shelley what was\n",
      "*minority \n",
      "enforce a decision of the\n",
      "*minority \n",
      "revolutionary civil disobedience toward the\n",
      "*minority \n",
      "occur when people speak about\n",
      "*minority \n",
      "a defiant speech sometimes more\n",
      "*financial \n",
      "are some examples of undesirable\n",
      "*financial \n",
      "the work and materials involved\n",
      "*financial \n",
      "is the average construction salary\n",
      "*financial \n",
      "of tuition in german private\n",
      "*minority \n",
      "in what month and year\n",
      "*minority \n",
      "of students of what ethnicity\n",
      "*minority \n",
      "after what higher learning model\n",
      "*financial \n",
      "what is the applicant admission\n",
      "*financial \n",
      "harvard stadium become the first\n",
      "*minority \n",
      "from a confederate cavalry unit\n",
      "*financial \n",
      "distinction does the bank of\n",
      "*minority \n",
      "people have wealth equal to\n",
      "*minority \n",
      "outcomes can even stable markets\n",
      "*financial \n",
      "key to getting the skills\n",
      "*financial \n",
      "view that labor-market flexibility improves\n",
      "*financial \n",
      "what is the level of\n",
      "*minority \n",
      "developed countries did british researchers\n",
      "*financial \n",
      "an increase in the income\n",
      "*financial \n",
      "n't economic growth sufficient for\n",
      "*minority \n",
      "definition of agency as it\n",
      "*financial \n",
      "episode of the new doctor\n",
      "*minority \n",
      "serial format change for the\n",
      "*minority \n",
      "brought up that the first\n",
      "*minority \n",
      "radio station did the doctor\n",
      "*minority \n",
      "third period of high viewership\n",
      "*financial \n",
      "year did the tenth doctor\n",
      "*financial \n",
      "what award was michelle gomez\n",
      "*financial \n",
      "will the barack obama presidential\n",
      "*financial \n",
      "public policy school found it\n",
      "*financial \n",
      "the university have a joint\n",
      "*financial \n",
      "how many fraternities form the\n",
      "*financial \n",
      "are currently on the university\n",
      "*minority \n",
      "when did the yuan people\n",
      "*financial \n",
      "when was the office of\n",
      "*minority \n",
      "what voyager said that mombasa\n",
      "*financial \n",
      "of the population live on\n",
      "*minority \n",
      "formed to introduce changes that\n",
      "*minority \n",
      "organizations issued the joint statement\n",
      "*financial \n",
      "michael oppenheimer have in the\n",
      "*minority \n",
      "do the protein products of\n",
      "*minority \n",
      "are we unsure of about\n",
      "*minority \n",
      "can be represented as the\n",
      "*minority \n",
      "year did pierre de fermat\n",
      "*financial \n",
      "the prime number p in\n",
      "*minority \n",
      "has goldbach 's conjecture been\n",
      "*financial \n",
      "p is prime that is\n",
      "*minority \n",
      "type of ring can prime\n",
      "*minority \n",
      "delta in the rhine delimited\n",
      "*financial \n",
      "is the boundary between the\n",
      "*minority \n",
      "the famous rock the rhine\n",
      "*financial \n",
      "is the english translation of\n",
      "*minority \n",
      "did natural sedimentation by the\n",
      "*minority \n",
      "the rhine considered to invaders\n",
      "*financial \n",
      "temporary home whilst the permanent\n",
      "*financial \n",
      "across scotland what do the\n",
      "*financial \n",
      "royal assent to the scotland\n",
      "*financial \n",
      "officer from whence are most\n",
      "*financial \n",
      "wishing to sit on the\n",
      "*minority \n",
      "what does a writer for\n",
      "*minority \n",
      "lawyer what profession did maududi\n",
      "*financial \n",
      "type of sanctions has the\n",
      "*financial \n",
      "the democratic process he strictly\n",
      "*financial \n",
      "position in the government does\n",
      "*minority \n",
      "what type of human does\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*minority \n",
      "what served as a justification\n",
      "*financial \n",
      "thought what was needed for\n",
      "*minority \n",
      "why was the student group\n",
      "*minority \n",
      "those tainted by what to\n",
      "*minority \n",
      "the umc believes that jesus\n",
      "*financial \n",
      "is the founder of the\n",
      "*minority \n",
      "if they are appointed as\n",
      "*minority \n",
      "the 2008 general conference what\n",
      "*minority \n",
      "where was marin 's second\n",
      "*minority \n",
      "pitt 's plan called for\n",
      "*minority \n",
      "laws of physics of galileo\n",
      "*financial \n",
      "force called when two forces\n",
      "*financial \n",
      "of a ship land according\n",
      "*financial \n",
      "earth in a formula about\n",
      "*minority \n",
      "what is the repulsive force\n",
      "*financial \n"
     ]
    }
   ],
   "source": [
    "start = 20\n",
    "samples = subsamples_in[start::total_batches][:min_batch_len]\n",
    "predictions = model.predict_on_batch(samples)\n",
    "for index, prediction in enumerate(predictions):\n",
    "    print(' '.join(index2word[index] for index in samples[index]))\n",
    "    pred_word = word2vec_model.similar_by_vector(prediction)[0][0]\n",
    "    sys.stdout.write(\"*\"+pred_word+\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    start = 27\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    predictions = model.predict_on_batch(subsamples_in[start::total_batches][:min_batch_len])\n",
    "    ytrue = subsamples_out[start::total_batches][:min_batch_len]\n",
    "    for index, prediction in enumerate(predictions):\n",
    "        pred_word = word2vec_model.similar_by_vector(prediction)[0][0]\n",
    "        true_word = word2vec_model.similar_by_vector(ytrue[index])[0][0]\n",
    "        sim = word2vec_model.similarity(pred_word, true_word)\n",
    "        if (sim >= 0.85):\n",
    "            correct += 1\n",
    "        count += 1\n",
    "    accur = float(correct/(count))\n",
    "    accuracy = 'accuracy = ' + str(float(accur))\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.22957198443579765\n"
     ]
    }
   ],
   "source": [
    "# n = no. of predictions\n",
    "accuracy = accuracy()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file_path = \"../weights/LSTM-2-512-Window-5-Batch-128-Epoch-10-Stateful/model_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file_path, 'w') as file:\n",
    "    file.write(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
